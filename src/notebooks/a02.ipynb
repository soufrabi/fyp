{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39be68d8-4e59-430b-81b9-a1e3092361c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import logging\n",
    "import gc\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00898722-f9a0-4738-9a4f-112bef7a3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c695d796-657d-46e8-b559-af2c4416fc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9aafdcdf-0452-4b2d-8120-4ffd94b4fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_garbage():\n",
    "    print(f'CPU memory            : {gc.collect()}')\n",
    "    print(f'CUDA memory allocated : {torch.cuda.memory_allocated()}' )\n",
    "    print(f'CUDA memory reserved  : {torch.cuda.memory_reserved()}')\n",
    "    print(torch.cuda.empty_cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6da2777-1a74-4c34-8e76-da3d0529de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU memory            : 381\n",
      "CUDA memory allocated : 698128896\n",
      "CUDA memory reserved  : 826277888\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "collect_garbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dd1ac5-0a14-4687-b8ff-9885f14571aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask = None ):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1,-2)) / math.sqrt(d_k)\n",
    "    # is permute(1,0,2,3) needed ?\n",
    "    \n",
    "    if mask is not None :\n",
    "        # logging.debug(f\"scaled type: {type(scaled)}\")\n",
    "        # logging.debug(f\"scaled.size() : {scaled.size()}\")\n",
    "        # logging.debug(f\"mask : {type(mask)}\")\n",
    "        # logging.debug(f\"mask.size(): {mask.size()}\")\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc0f85a6-57bb-4994-ae6c-bcbf418e97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 96]) torch.Size([15, 4, 96]) torch.Size([15, 4, 96])\n"
     ]
    }
   ],
   "source": [
    "q,k,v = [ torch.rand(15,4,96) for _ in range(3)]\n",
    "print(q.shape, k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d009d624-3cdd-46de-be36-44d05a972575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 96]) torch.Size([15, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q,k,v)\n",
    "print(values.size(), attention.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ae93c5-97ff-448e-b66c-a3e1b9043a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model, 3*d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask = None ):\n",
    "        logging.debug(\"MultiHeadAttention BEGINS\")\n",
    "        batch_size, max_sequence_length, d_model = x.size()\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        logging.debug(f\"mask.size() : {mask.size()}\" if mask is not None else \"mask is None\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim )\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0,2,1,3)\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        q,k,v = qkv.chunk(3, dim = -1)\n",
    "        logging.debug(f\"q.size(): {q.size()}, k.size(): {k.size()}, v.size(): {v.size()}\")\n",
    "        values, attention = scaled_dot_product(q,k,v, mask = mask)\n",
    "        logging.debug(f\"values.size(): {values.size()}, attention.size(): {attention.size()}\")\n",
    "        values = values.reshape(batch_size, max_sequence_length, self.d_model)     \n",
    "        logging.debug(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        logging.debug(f\"out.size(): {out.size()}\")\n",
    "        logging.debug(\"MultiHeadAttention ENDS\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945d9f40-7404-46f5-b670-732993a6034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5908f00b-d843-4340-b40b-ff766db9d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:mask is None\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 8, 4, 288])\n",
      "DEBUG:root:q.size(): torch.Size([15, 8, 4, 96]), k.size(): torch.Size([15, 8, 4, 96]), v.size(): torch.Size([15, 8, 4, 96])\n",
      "DEBUG:root:values.size(): torch.Size([15, 8, 4, 96]), attention.size(): torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:values.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(15,4,768)\n",
    "mha = MultiHeadAttention(d_model = 768, num_heads = 8)\n",
    "with torch.no_grad():\n",
    "    t2 = mha(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9659d27c-00ec-4879-9094-109503bff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps = 1e-5):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        self.parameters_shape = parameters_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        logging.debug(\"LayerNormalization BEGINS\")\n",
    "        dims = [-(i+1) for i in range(len(self.parameters_shape))]\n",
    "        mean = x.mean(dim = dims, keepdim= True)\n",
    "        logging.debug(f\"mean.size(): {mean.size()}\")\n",
    "        var = ((x - mean)**2).mean(dim = dims, keepdim = True)\n",
    "        logging.debug(f\"var.size(): {var.size()}\")\n",
    "        std = (var + self.eps).sqrt()\n",
    "        logging.debug(f\"std.size(): {std.size()}\")\n",
    "        y = (x - mean) / std\n",
    "        logging.debug(f\"y.size() : {y.size()}\")\n",
    "        out = self.gamma * y + self.beta\n",
    "        logging.debug(f\"out.size(): {out.size()}\")\n",
    "\n",
    "        logging.debug(\"LayerNormalization ENDS\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e43aa3-6e6c-4eed-a8d5-7b4913d80466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(15,4,768)\n",
    "ln_layer = LayerNormalization(parameters_shape=[768], eps = 1e-5)\n",
    "with torch.no_grad():\n",
    "    t2 = ln_layer(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35b9564a-8c0c-46f0-a833-8aa33159d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob = 0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logging.debug(\"PositionwiseFeedForward BEGINS\")\n",
    "        x = self.linear1(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.relu(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.dropout(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.linear2(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        logging.debug(\"PositionwiseFeedForward ENDS\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b7992f-8293-402f-b885-ca4f585c40b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "pff_layer = PositionwiseFeedForward(d_model = 768,\n",
    "                                   hidden = 768,\n",
    "                                   drop_prob=0.1)\n",
    "t1 = torch.rand(15,4,768)\n",
    "with torch.no_grad():\n",
    "    t2 = pff_layer(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4bcebda-a44a-431c-b3e2-294d8ca921a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(d_model = d_model,\n",
    "                                            num_heads=num_heads) \n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.norm1 = LayerNormalization(parameters_shape = [d_model])\n",
    "       \n",
    "        self.ffn = PositionwiseFeedForward(d_model = d_model,\n",
    "                                           hidden = ffn_hidden,\n",
    "                                           drop_prob = drop_prob)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape = [d_model]) \n",
    "       \n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        logging.debug(\"EncoderLayer BEGINS\")\n",
    "        r_x = x\n",
    "        x = self.attention(x, mask = self_attention_mask)\n",
    "        # logging.debug(f\"x.size() : {x.size()}\")\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + r_x)\n",
    "\n",
    "        r_x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + r_x)\n",
    "        logging.debug(\"EncoderLayer ENDS\")\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eac5fd71-6872-4e21-8c1d-feb70f0b6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 8, 4, 288])\n",
      "DEBUG:root:q.size(): torch.Size([15, 8, 4, 96]), k.size(): torch.Size([15, 8, 4, 96]), v.size(): torch.Size([15, 8, 4, 96])\n",
      "DEBUG:root:values.size(): torch.Size([15, 8, 4, 96]), attention.size(): torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:values.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "enc_layer = EncoderLayer(d_model = 768,\n",
    "                        ffn_hidden = 768,\n",
    "                        num_heads = 8,\n",
    "                        drop_prob = 0.1)\n",
    "t1 = torch.rand(15,4,768)\n",
    "# self_attention_mask_t2 = torch.rand(15,4,4)\n",
    "self_attention_mask_t2 = torch.rand(15,8,4,4)\n",
    "with torch.no_grad():\n",
    "    t2 = enc_layer(t1, self_attention_mask_t2)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c743e9fb-e5f9-4d7b-bb0a-6280e230ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialEncoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, self_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, self_attention_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe039681-7fd5-482e-ab8c-a4ce480c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = SequentialEncoder(*[\n",
    "                EncoderLayer(\n",
    "                    d_model=d_model,\n",
    "                    ffn_hidden = ffn_hidden,\n",
    "                    num_heads = num_heads,\n",
    "                    drop_prob = drop_prob,\n",
    "                    )\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        x = self.layers(x,self_attention_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "417f58b4-b791-4637-8ba9-d9e9f3f9a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1ec139-3c66-45ee-9c92-c70c7fff3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e521290-4940-451f-a183-a416d610eeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512]) torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(1,4,512)\n",
    "self_attention_mask_t2 = torch.rand(1,4,4)\n",
    "enc = Encoder(d_model = 512,\n",
    "              ffn_hidden = 512,\n",
    "              num_heads = 8,\n",
    "              drop_prob = 0.1,\n",
    "              num_layers = 6)\n",
    "with torch.no_grad():\n",
    "    t2 = enc(t1, self_attention_mask_t2)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e62c65e-5992-4767-b0db-f7405831673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.kv_layer = nn.Linear(d_model, 2*d_model)\n",
    "        self.q_layer = nn.Linear(d_model, d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, y, mask):\n",
    "        logging.debug(\"MultiHeadCrossAttention BEGINS\")\n",
    "        batch_size, sequence_length, d_model = x.size()\n",
    "        kv = self.kv_layer(x)\n",
    "        q = self.q_layer(y)\n",
    "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2*self.head_dim)\n",
    "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        kv = kv.permute(0,2,1,3)\n",
    "        q = q.permute(0,2,1,3)\n",
    "        k,v = kv.chunk(2, dim = -1)\n",
    "        \"\"\" We don't need the mask in cross attention, removing in outerfunction but why ?\"\"\"\n",
    "        values, attention = scaled_dot_product(q,k,v,mask = mask)\n",
    "        values = values.permute(0,2,1,3)\n",
    "        values = values.reshape(batch_size, sequence_length, d_model)\n",
    "        out = self.linear_layer(values)\n",
    "        logging.debug(\"MultiHeadCrossAttention ENDS\")\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac3c512-5de1-4ff1-a23e-1b697f61b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model = d_model,\n",
    "                                                 num_heads = num_heads,\n",
    "                                                )\n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "\n",
    "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model = d_model,\n",
    "                                                                num_heads = num_heads)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "\n",
    "        self.ffn = PositionwiseFeedForward(d_model = d_model,\n",
    "                                           hidden= ffn_hidden,\n",
    "                                           drop_prob = drop_prob)\n",
    "        self.dropout3 = nn.Dropout(p = drop_prob)\n",
    "        self.norm3 = LayerNormalization(parameters_shape = [d_model])\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        r_y = y\n",
    "        y = self.self_attention(y, mask = self_attention_mask)\n",
    "        y = self.dropout1(y)\n",
    "        y = self.norm1(y + r_y)\n",
    "\n",
    "        r_y = y\n",
    "        y = self.encoder_decoder_attention(x,y,mask = cross_attention_mask)\n",
    "        y = self.dropout2(y)\n",
    "        y = self.norm2(y + r_y)\n",
    "\n",
    "        r_y = y\n",
    "        y = self.ffn(y)\n",
    "        y = self.dropout3(y)\n",
    "        y = self.norm3(y + r_y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8598637-10a5-403c-85c0-18472fac4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDecoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08b202d6-0ebd-4cb9-b2c3-68c583ac58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers,):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layers = SequentialDecoder(*[\n",
    "            DecoderLayer(d_model=d_model,\n",
    "                         ffn_hidden=ffn_hidden,\n",
    "                         num_heads= num_heads,\n",
    "                         drop_prob = drop_prob,\n",
    "                        )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self,\n",
    "                x,\n",
    "                y,\n",
    "                self_attention_mask,\n",
    "                cross_attention_mask):\n",
    "        logging.debug(\"Decoder BEGINS\")\n",
    "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
    "        logging.debug(\"Decoder ENDS\")\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de52658a-e7ab-43f7-860a-ead1f0416939",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63444188-8db0-42d8-bd40-4a875c99309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45b97fe1-4424-42e9-b59e-0547ef786e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512]) torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "t1_x = torch.rand(1,4,512)\n",
    "t1_y = torch.rand(1,4,512)\n",
    "t1_self_attention_mask = torch.rand(1,4,4)\n",
    "t1_cross_attention_mask = torch.rand(1,4,4)\n",
    "\n",
    "dec = Decoder(d_model=512,\n",
    "              ffn_hidden=512,\n",
    "              num_heads=8,\n",
    "              drop_prob=0.1,\n",
    "              num_layers = 4)\n",
    "with torch.no_grad():\n",
    "    t2 = dec(x = t1_x,\n",
    "             y = t1_y,\n",
    "             self_attention_mask = t1_self_attention_mask,\n",
    "             cross_attention_mask = t1_cross_attention_mask,)\n",
    "    print(t1.shape, t2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad99582f-1019-406f-918e-7d089c3033bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers,):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(d_model = d_model,\n",
    "                              ffn_hidden = ffn_hidden,\n",
    "                              num_heads = num_heads,\n",
    "                              drop_prob = drop_prob,\n",
    "                              num_layers = num_layers)\n",
    "        self.decoder = Decoder(d_model = d_model,\n",
    "                              ffn_hidden = ffn_hidden,\n",
    "                              num_heads = num_heads,\n",
    "                              drop_prob = drop_prob,\n",
    "                              num_layers = num_layers)\n",
    "\n",
    "    def forward(self,\n",
    "                x,\n",
    "                y,\n",
    "                encoder_self_attention_mask = None,\n",
    "                decoder_self_attention_mask = None,\n",
    "                decoder_cross_attention_mask = None,):\n",
    "        logging.debug(\"Transformer BEGINS\")\n",
    "        x = self.encoder(x,\n",
    "                         encoder_self_attention_mask)\n",
    "        out = self.decoder(x,\n",
    "                           y,\n",
    "                           decoder_self_attention_mask,\n",
    "                           decoder_cross_attention_mask)\n",
    "        logging.debug(\"Transformer ENDS\")\n",
    "        # need a linear layer that maps to vocabulary size\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b6f7906-8d71-49c7-9a8b-b47c44a428b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 768]) torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "trfm = Transformer(d_model = 768,\n",
    "                  ffn_hidden = 768,\n",
    "                  num_heads = 8,\n",
    "                  drop_prob = 0.1,\n",
    "                  num_layers = 1)\n",
    "\n",
    "t1_x = torch.rand(1,4,768)\n",
    "t1_y = torch.rand(1,4,768)\n",
    "t1_encoder_self_attention = torch.rand(1,4,4)\n",
    "t1_decoder_self_attention = torch.rand(1,4,4)\n",
    "t1_decoder_cross_attention = torch.rand(1,4,4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    t2 = trfm(t1_x,\n",
    "             t1_y,\n",
    "             t1_encoder_self_attention,\n",
    "             t1_decoder_self_attention,\n",
    "             t1_decoder_cross_attention)\n",
    "    print(t1_x.shape, t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5517c3cd-e23f-4039-ad9e-cd286c2ffedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:nn.Module, num_epochs: int, device: torch.device):\n",
    "    # number of sentences in text\n",
    "    batch_size = 15\n",
    "    # dimensions of each word\n",
    "    d_model = 768\n",
    "    # number of words in a sentence\n",
    "    sequence_length = 4\n",
    "    # number of heads in multi head attention\n",
    "    num_heads = 8\n",
    "\n",
    "    # train and validation losses\n",
    "    train_losses, val_losses = [],[]\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\n",
    "    \n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        \"\"\" Training Phase \"\"\"\n",
    "        # Set model to train mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        x = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "        y = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "        encoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "        decoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "        decoder_cross_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, y, encoder_self_attention_mask, decoder_cross_attention_mask, decoder_cross_attention_mask)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f'loss.item(): {loss.item()}')\n",
    "        # running_loss += loss.item() * y.size(0)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / 1\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        \"\"\" Validation Phase \"\"\"\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # reusing past values\n",
    "            x = torch.rand(batch_size,sequence_length, d_model).to(device)\n",
    "            y = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "            encoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_cross_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "\n",
    "            output = model(x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "        val_loss = running_loss / 1\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Log epoch stats\n",
    "        logging.info(f\"Epoch {epoch+1}/{num_epochs} ; Train loss : {train_loss} ; Valid loss : {val_loss}\")\n",
    "\n",
    "    # returning losses\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a332ed7c-23de-4651-a3be-de1d0c2fdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trfm_model = Transformer(d_model=768,\n",
    "                   ffn_hidden=768,\n",
    "                   num_heads = 8,\n",
    "                   drop_prob=0.1,\n",
    "                   num_layers=6).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f2d8ad7-79db-4e19-9e6a-068fd162a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trfm_model)\n",
    "# with open(\"model.txt\", \"w\") as f:\n",
    "#     f.write(str(trfm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59e95ac8-4834-498f-9950-4898c982a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bf255c2cd44e5f8f43ba3411167784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(model = trfm_model, num_epochs = 100, device = get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752201a-3d16-413e-8c43-f22dd8d94e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_losses, label = \"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ab9acee-b4e4-436b-8bf6-9869a092ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "collect_garbage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
