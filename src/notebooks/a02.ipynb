{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39be68d8-4e59-430b-81b9-a1e3092361c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import logging\n",
    "import gc\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tiktoken\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00898722-f9a0-4738-9a4f-112bef7a3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c695d796-657d-46e8-b559-af2c4416fc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9aafdcdf-0452-4b2d-8120-4ffd94b4fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_garbage():\n",
    "    print(f'CPU memory            : {gc.collect()}')\n",
    "    print(f'CUDA memory allocated : {torch.cuda.memory_allocated()}' )\n",
    "    print(f'CUDA memory reserved  : {torch.cuda.memory_reserved()}')\n",
    "    print(torch.cuda.empty_cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6da2777-1a74-4c34-8e76-da3d0529de98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU memory            : 0\n",
      "CUDA memory allocated : 12513280\n",
      "CUDA memory reserved  : 44040192\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "collect_garbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0e7826a-b1fc-4656-8d75-f26752d1e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngLang:\n",
    "    # # Sentence tokenization\n",
    "    \n",
    "    START_TOKEN = '<START>'\n",
    "    PADDING_TOKEN = '<PADDING>'\n",
    "    END_TOKEN = '<END>'\n",
    "    \n",
    "    \n",
    "    english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                            '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                            ':', '<', '=', '>', '?', '@', \n",
    "                            'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', \n",
    "                            'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', \n",
    "                            'Y', 'Z',\n",
    "                            '[', '\\\\', ']', '^', '_', '`', \n",
    "                            'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                            'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                            'y', 'z', \n",
    "                            '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "    vocab_size = len(english_vocabulary)\n",
    "\n",
    "    \"\"\" language <-> index \"\"\"\n",
    "    english_to_index = {v:k for k,v in enumerate(english_vocabulary)}\n",
    "    index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d058fe4-ab9e-46ba-b553-d2c169827634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 97 97\n"
     ]
    }
   ],
   "source": [
    "print(EngLang.english_to_index.__len__(), EngLang.index_to_english.__len__(), EngLang.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e51fd21-a0fa-46d8-af8a-0eb473667104",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01345c87-d803-4e9d-a718-53f28c739a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c1714e3-adcf-4e63-a385-ef017fc2b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                batch_size,\n",
    "                max_sequence_length,\n",
    "                char_per_sequence,\n",
    "                d_model,\n",
    "                language_to_index,\n",
    "                START_TOKEN,\n",
    "                END_TOKEN,\n",
    "                PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        # super(SentenceEmbedding,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.char_per_sequence = char_per_sequence\n",
    "        self.d_model = d_model\n",
    "        self.language_to_index = language_to_index\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "\n",
    "        self.linear_layer = nn.Linear( self.char_per_sequence, self.max_sequence_length * self.d_model)\n",
    "        self.device = get_device()\n",
    "\n",
    "    # def tokenize_sentence(sentence:str, start_token):\n",
    "    #     pass\n",
    "    def generate_sents_indices(self, sents:List[str], start_token: bool, end_token:bool):\n",
    "        sents_indices = []\n",
    "        for sent in sents :\n",
    "            sent_indices = [ self.language_to_index[ch] for ch in sent if ch in self.language_to_index ]\n",
    "            if start_token :\n",
    "                sent_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
    "\n",
    "            sent_indices = sent_indices[:self.char_per_sequence-1]\n",
    "            # if len(sent_indices) > self.max_sequence_length + 1:\n",
    "                # sent_indices = sent_indices[:self.max_sequence_length-1]\n",
    "            if end_token :\n",
    "                sent_indices.append(self.language_to_index[self.END_TOKEN])\n",
    "            for _ in range(len(sent_indices), self.char_per_sequence):\n",
    "                sent_indices.append(self.language_to_index[self.PADDING_TOKEN])\n",
    "            \n",
    "            sents_indices.append(sent_indices)\n",
    "\n",
    "        return sents_indices\n",
    "\n",
    "    def forward(self,\n",
    "                text:str,\n",
    "                start_token:bool,\n",
    "                end_token:bool):\n",
    "        # logging.debug(f\"Text : {text}\")\n",
    "        \n",
    "        sents = sent_tokenize(text)\n",
    "        # Removing training sentences\n",
    "        if len(sents) > self.batch_size :\n",
    "            sents = sents[:self.batch_size]\n",
    "        logging.debug(f\"Sentences : {sents}\")\n",
    "\n",
    "        sents_indices = self.generate_sents_indices(sents, start_token, end_token)\n",
    "        logging.debug(f\"sents_indices : {sents_indices}\")\n",
    "\n",
    "        # for sent_indices in sents_indices :\n",
    "        #     print(len(sent_indices)\n",
    "\n",
    "\n",
    "\n",
    "        sents_tokenized = torch.tensor(sents_indices, dtype = torch.float32, device = self.device)\n",
    "        logging.debug(f'sents_tokenized.size() : {sents_tokenized.size()}, sents_tokenize.device : {sents_tokenized.device}')\n",
    "\n",
    "        logging.debug(f\"Linear Layer\")\n",
    "        logging.debug(f\"linear_layer.device : {self.linear_layer.weight.device}\")\n",
    "        sents_tokenized = self.linear_layer(sents_tokenized)\n",
    "        logging.debug(f'sents_tokenized.size() : {sents_tokenized.size()}')\n",
    "        sents_tokenized = sents_tokenized.reshape(len(sents),\n",
    "                                                  self.max_sequence_length,\n",
    "                                                  self.d_model)\n",
    "        logging.debug(f'sents_tokenized.size() : {sents_tokenized.size()}')\n",
    "\n",
    "        fill_tensor = torch.full( (self.batch_size - len(sents), self.max_sequence_length, self.d_model )  , self.language_to_index[self.PADDING_TOKEN]).to( self.device )\n",
    "        logging.debug(f'fill_tensor.size() : {fill_tensor.size()}')\n",
    "\n",
    "        out = torch.cat((sents_tokenized, fill_tensor), dim = 0)\n",
    "        logging.debug(f'out.size() : {out.size()}')\n",
    "        return out\n",
    "        # return torch.rand(self.batch_size,\n",
    "        #                   self.max_sequence_length,\n",
    "        #                   self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96f16903-c5e1-4ea8-85b5-83e821ef2ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 Octob\n",
      "1211\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\"\"\"\n",
    "print(text[:100])\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76de828b-cf6a-4616-81be-4638bc425ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20, 768])\n"
     ]
    }
   ],
   "source": [
    "sentence_embedding = SentenceEmbedding(\n",
    "    batch_size = 64,\n",
    "    max_sequence_length = 20,\n",
    "    char_per_sequence = 64,\n",
    "    d_model = 768,\n",
    "    language_to_index = EngLang.english_to_index,\n",
    "    START_TOKEN = EngLang.START_TOKEN,\n",
    "    END_TOKEN = EngLang.END_TOKEN,\n",
    "    PADDING_TOKEN = EngLang.PADDING_TOKEN,\n",
    ").to(get_device())\n",
    "\n",
    "with torch.no_grad():\n",
    "    t2 = sentence_embedding(text, start_token = True, end_token = True)\n",
    "    print(t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60dd1ac5-0a14-4687-b8ff-9885f14571aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask = None ):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1,-2)) / math.sqrt(d_k)\n",
    "    # is permute(1,0,2,3) needed ?\n",
    "    \n",
    "    if mask is not None :\n",
    "        logging.debug(f\"scaled .size() : {scaled.size()}  type : {type(scaled)}\")\n",
    "        logging.debug(f\"mask .size(): {mask.size()} type : {type(mask)}\")\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim = -1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc0f85a6-57bb-4994-ae6c-bcbf418e97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 96]) torch.Size([15, 4, 96]) torch.Size([15, 4, 96])\n"
     ]
    }
   ],
   "source": [
    "q,k,v = [ torch.rand(15,4,96) for _ in range(3)]\n",
    "print(q.shape, k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d009d624-3cdd-46de-be36-44d05a972575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 96]) torch.Size([15, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q,k,v)\n",
    "print(values.size(), attention.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9ae93c5-97ff-448e-b66c-a3e1b9043a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(d_model, 3*d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask = None ):\n",
    "        logging.debug(\"MultiHeadAttention BEGINS\")\n",
    "        batch_size, max_sequence_length, d_model = x.size()\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        logging.debug(f\"mask.size() : {mask.size()}\" if mask is not None else \"mask is None\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim )\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0,2,1,3)\n",
    "        logging.debug(f\"qkv.size(): {qkv.size()}\")\n",
    "        q,k,v = qkv.chunk(3, dim = -1)\n",
    "        logging.debug(f\"q.size(): {q.size()}, k.size(): {k.size()}, v.size(): {v.size()}\")\n",
    "        values, attention = scaled_dot_product(q,k,v, mask = mask)\n",
    "        logging.debug(f\"values.size(): {values.size()}, attention.size(): {attention.size()}\")\n",
    "        values = values.reshape(batch_size, max_sequence_length, self.d_model)     \n",
    "        logging.debug(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        logging.debug(f\"out.size(): {out.size()}\")\n",
    "        logging.debug(\"MultiHeadAttention ENDS\")\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "945d9f40-7404-46f5-b670-732993a6034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5908f00b-d843-4340-b40b-ff766db9d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:mask is None\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 8, 4, 288])\n",
      "DEBUG:root:q.size(): torch.Size([15, 8, 4, 96]), k.size(): torch.Size([15, 8, 4, 96]), v.size(): torch.Size([15, 8, 4, 96])\n",
      "DEBUG:root:values.size(): torch.Size([15, 8, 4, 96]), attention.size(): torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:values.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(15,4,768)\n",
    "mha = MultiHeadAttention(d_model = 768, num_heads = 8)\n",
    "with torch.no_grad():\n",
    "    t2 = mha(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9659d27c-00ec-4879-9094-109503bff98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, parameters_shape, eps = 1e-5):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        self.parameters_shape = parameters_shape\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        logging.debug(\"LayerNormalization BEGINS\")\n",
    "        dims = [-(i+1) for i in range(len(self.parameters_shape))]\n",
    "        mean = x.mean(dim = dims, keepdim= True)\n",
    "        logging.debug(f\"mean.size(): {mean.size()}\")\n",
    "        var = ((x - mean)**2).mean(dim = dims, keepdim = True)\n",
    "        logging.debug(f\"var.size(): {var.size()}\")\n",
    "        std = (var + self.eps).sqrt()\n",
    "        logging.debug(f\"std.size(): {std.size()}\")\n",
    "        y = (x - mean) / std\n",
    "        logging.debug(f\"y.size() : {y.size()}\")\n",
    "        out = self.gamma * y + self.beta\n",
    "        logging.debug(f\"out.size(): {out.size()}\")\n",
    "\n",
    "        logging.debug(\"LayerNormalization ENDS\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67e43aa3-6e6c-4eed-a8d5-7b4913d80466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(15,4,768)\n",
    "ln_layer = LayerNormalization(parameters_shape=[768], eps = 1e-5)\n",
    "with torch.no_grad():\n",
    "    t2 = ln_layer(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35b9564a-8c0c-46f0-a833-8aa33159d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, hidden, drop_prob = 0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logging.debug(\"PositionwiseFeedForward BEGINS\")\n",
    "        x = self.linear1(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.relu(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.dropout(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        x = self.linear2(x)\n",
    "        logging.debug(f\"x.size(): {x.size()}\")\n",
    "        logging.debug(\"PositionwiseFeedForward ENDS\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27b7992f-8293-402f-b885-ca4f585c40b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "pff_layer = PositionwiseFeedForward(d_model = 768,\n",
    "                                   hidden = 768,\n",
    "                                   drop_prob=0.1)\n",
    "t1 = torch.rand(15,4,768)\n",
    "with torch.no_grad():\n",
    "    t2 = pff_layer(t1)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4bcebda-a44a-431c-b3e2-294d8ca921a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention(d_model = d_model,\n",
    "                                            num_heads=num_heads) \n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.norm1 = LayerNormalization(parameters_shape = [d_model])\n",
    "       \n",
    "        self.ffn = PositionwiseFeedForward(d_model = d_model,\n",
    "                                           hidden = ffn_hidden,\n",
    "                                           drop_prob = drop_prob)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape = [d_model]) \n",
    "       \n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        logging.debug(\"EncoderLayer BEGINS\")\n",
    "        r_x = x\n",
    "        x = self.attention(x, mask = self_attention_mask)\n",
    "        # logging.debug(f\"x.size() : {x.size()}\")\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + r_x)\n",
    "\n",
    "        r_x = x\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + r_x)\n",
    "        logging.debug(\"EncoderLayer ENDS\")\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eac5fd71-6872-4e21-8c1d-feb70f0b6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 4, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([15, 8, 4, 288])\n",
      "DEBUG:root:q.size(): torch.Size([15, 8, 4, 96]), k.size(): torch.Size([15, 8, 4, 96]), v.size(): torch.Size([15, 8, 4, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([15, 8, 4, 4])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([15, 8, 4, 4]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([15, 8, 4, 96]), attention.size(): torch.Size([15, 8, 4, 4])\n",
      "DEBUG:root:values.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:x.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:var.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:std.size(): torch.Size([15, 4, 1])\n",
      "DEBUG:root:y.size() : torch.Size([15, 4, 768])\n",
      "DEBUG:root:out.size(): torch.Size([15, 4, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 4, 768]) torch.Size([15, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "enc_layer = EncoderLayer(d_model = 768,\n",
    "                        ffn_hidden = 768,\n",
    "                        num_heads = 8,\n",
    "                        drop_prob = 0.1)\n",
    "t1 = torch.rand(15,4,768)\n",
    "# self_attention_mask_t2 = torch.rand(15,4,4)\n",
    "self_attention_mask_t2 = torch.rand(15,8,4,4)\n",
    "with torch.no_grad():\n",
    "    t2 = enc_layer(t1, self_attention_mask_t2)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c743e9fb-e5f9-4d7b-bb0a-6280e230ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialEncoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, self_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            x = module(x, self_attention_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe039681-7fd5-482e-ab8c-a4ce480c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = SequentialEncoder(*[\n",
    "                EncoderLayer(\n",
    "                    d_model=d_model,\n",
    "                    ffn_hidden = ffn_hidden,\n",
    "                    num_heads = num_heads,\n",
    "                    drop_prob = drop_prob,\n",
    "                    )\n",
    "                for _ in range(num_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        x = self.layers(x,self_attention_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "417f58b4-b791-4637-8ba9-d9e9f3f9a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da1ec139-3c66-45ee-9c92-c70c7fff3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e521290-4940-451f-a183-a416d610eeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512]) torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(1,4,512)\n",
    "self_attention_mask_t2 = torch.rand(1,4,4)\n",
    "enc = Encoder(d_model = 512,\n",
    "              ffn_hidden = 512,\n",
    "              num_heads = 8,\n",
    "              drop_prob = 0.1,\n",
    "              num_layers = 6)\n",
    "with torch.no_grad():\n",
    "    t2 = enc(t1, self_attention_mask_t2)\n",
    "print(t1.size(), t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e62c65e-5992-4767-b0db-f7405831673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadCrossAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.kv_layer = nn.Linear(d_model, 2*d_model)\n",
    "        self.q_layer = nn.Linear(d_model, d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, y, mask):\n",
    "        logging.debug(\"MultiHeadCrossAttention BEGINS\")\n",
    "        batch_size, sequence_length, d_model = x.size()\n",
    "        kv = self.kv_layer(x)\n",
    "        q = self.q_layer(y)\n",
    "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2*self.head_dim)\n",
    "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
    "        kv = kv.permute(0,2,1,3)\n",
    "        q = q.permute(0,2,1,3)\n",
    "        k,v = kv.chunk(2, dim = -1)\n",
    "        \"\"\" We don't need the mask in cross attention, removing in outerfunction but why ?\"\"\"\n",
    "        values, attention = scaled_dot_product(q,k,v,mask = mask)\n",
    "        values = values.permute(0,2,1,3)\n",
    "        values = values.reshape(batch_size, sequence_length, d_model)\n",
    "        out = self.linear_layer(values)\n",
    "        logging.debug(\"MultiHeadCrossAttention ENDS\")\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ac3c512-5de1-4ff1-a23e-1b697f61b861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attention = MultiHeadAttention(d_model = d_model,\n",
    "                                                 num_heads = num_heads,\n",
    "                                                )\n",
    "        self.dropout1 = nn.Dropout(p = drop_prob)\n",
    "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
    "\n",
    "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model = d_model,\n",
    "                                                                num_heads = num_heads)\n",
    "        self.dropout2 = nn.Dropout(p = drop_prob)\n",
    "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
    "\n",
    "        self.ffn = PositionwiseFeedForward(d_model = d_model,\n",
    "                                           hidden= ffn_hidden,\n",
    "                                           drop_prob = drop_prob)\n",
    "        self.dropout3 = nn.Dropout(p = drop_prob)\n",
    "        self.norm3 = LayerNormalization(parameters_shape = [d_model])\n",
    "\n",
    "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
    "        r_y = y\n",
    "        y = self.self_attention(y, mask = self_attention_mask)\n",
    "        y = self.dropout1(y)\n",
    "        y = self.norm1(y + r_y)\n",
    "\n",
    "        r_y = y\n",
    "        y = self.encoder_decoder_attention(x,y,mask = cross_attention_mask)\n",
    "        y = self.dropout2(y)\n",
    "        y = self.norm2(y + r_y)\n",
    "\n",
    "        r_y = y\n",
    "        y = self.ffn(y)\n",
    "        y = self.dropout3(y)\n",
    "        y = self.norm3(y + r_y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8598637-10a5-403c-85c0-18472fac4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialDecoder(nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
    "        for module in self._modules.values():\n",
    "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08b202d6-0ebd-4cb9-b2c3-68c583ac58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers,):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.layers = SequentialDecoder(*[\n",
    "            DecoderLayer(d_model=d_model,\n",
    "                         ffn_hidden=ffn_hidden,\n",
    "                         num_heads= num_heads,\n",
    "                         drop_prob = drop_prob,\n",
    "                        )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self,\n",
    "                x,\n",
    "                y,\n",
    "                self_attention_mask,\n",
    "                cross_attention_mask):\n",
    "        logging.debug(\"Decoder BEGINS\")\n",
    "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
    "        logging.debug(\"Decoder ENDS\")\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de52658a-e7ab-43f7-860a-ead1f0416939",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63444188-8db0-42d8-bd40-4a875c99309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "45b97fe1-4424-42e9-b59e-0547ef786e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 512]) torch.Size([1, 4, 512])\n"
     ]
    }
   ],
   "source": [
    "t1_x = torch.rand(1,4,512)\n",
    "t1_y = torch.rand(1,4,512)\n",
    "t1_self_attention_mask = torch.rand(1,4,4)\n",
    "t1_cross_attention_mask = torch.rand(1,4,4)\n",
    "\n",
    "dec = Decoder(d_model=512,\n",
    "              ffn_hidden=512,\n",
    "              num_heads=8,\n",
    "              drop_prob=0.1,\n",
    "              num_layers = 4)\n",
    "with torch.no_grad():\n",
    "    t2 = dec(x = t1_x,\n",
    "             y = t1_y,\n",
    "             self_attention_mask = t1_self_attention_mask,\n",
    "             cross_attention_mask = t1_cross_attention_mask,)\n",
    "    print(t1.shape, t2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14c05709-32e6-4623-b89a-6f8ba678f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "606f60ce-21c5-44f7-9b9a-344cb1c0b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ad99582f-1019-406f-918e-7d089c3033bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 max_sequence_length,\n",
    "                 char_per_sequence,\n",
    "                 d_model,\n",
    "                 ffn_hidden,\n",
    "                 num_heads,\n",
    "                 drop_prob,\n",
    "                 num_layers,):\n",
    "        super(Transformer, self).__init__()\n",
    "        # self.enc_embedding = SentenceEmbedding(batch_size = batch_size,\n",
    "        #                                        max_sequence_length=max_sequence_length,\n",
    "        #                                        char_per_sequence=char_per_sequence,\n",
    "        #                                        d_model=d_model,\n",
    "        #                                        language_to_index=EngLang.english_to_index,\n",
    "        #                                        START_TOKEN=EngLang.START_TOKEN,\n",
    "        #                                       END_TOKEN=EngLang.END_TOKEN,\n",
    "        #                                       PADDING_TOKEN=EngLang.PADDING_TOKEN)\n",
    "        # self.dec_embedding = SentenceEmbedding(batch_size = batch_size,\n",
    "        #                                       max_sequence_length=max_sequence_length,\n",
    "        #                                       char_per_sequence=char_per_sequence,\n",
    "        #                                       d_model = d_model,\n",
    "        #                                       language_to_index=EngLang.english_to_index,\n",
    "        #                                       START_TOKEN=EngLang.START_TOKEN,\n",
    "        #                                       END_TOKEN = EngLang.END_TOKEN,\n",
    "        #                                       PADDING_TOKEN = EngLang.PADDING_TOKEN)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "        self.encoder = Encoder(d_model = d_model,\n",
    "                              ffn_hidden = ffn_hidden,\n",
    "                              num_heads = num_heads,\n",
    "                              drop_prob = drop_prob,\n",
    "                              num_layers = num_layers)\n",
    "        self.decoder = Decoder(d_model = d_model,\n",
    "                              ffn_hidden = ffn_hidden,\n",
    "                              num_heads = num_heads,\n",
    "                              drop_prob = drop_prob,\n",
    "                              num_layers = num_layers)\n",
    "\n",
    "        token_per_sequence = char_per_sequence // 6\n",
    "        self.linear_layer = nn.Linear(max_sequence_length * d_model, token_per_sequence)\n",
    "\n",
    "    def tokenize(self, x:str)-> torch.Tensor:\n",
    "        EOT_TOKEN = self.tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "\n",
    "        x = self.tokenizer.encode(x)\n",
    "        logging.debug(f'len(x) : {len(x)}')\n",
    "        x.append( EOT_TOKEN )\n",
    "        logging.debug(f'len(x) : {len(x)}')\n",
    "        x = torch.tensor(x, dtype = torch.float32, device = get_device())\n",
    "        pad = torch.full( (self.batch_size * self.max_sequence_length* self.d_model -  len(x) , ) , EOT_TOKEN ).to(get_device())\n",
    "        logging.debug(f'pad.size() : {pad.size()}')\n",
    "        x = torch.cat( (x,pad,), dim=0)\n",
    "        logging.debug(f'x.size() : {x.size()}')\n",
    "        x = x.reshape(self.batch_size, self.max_sequence_length, self.d_model)\n",
    "        logging.debug(f'x.size() : {x.size()}')\n",
    "\n",
    "        return x\n",
    "        \n",
    "    def forward(self,\n",
    "                x,\n",
    "                y,\n",
    "                encoder_self_attention_mask = None,\n",
    "                decoder_self_attention_mask = None,\n",
    "                decoder_cross_attention_mask = None,):\n",
    "        logging.debug(\"Transformer BEGINS\")\n",
    "\n",
    "        \n",
    "        \n",
    "        # x = self.enc_embedding(x, start_token = True, end_token = True)\n",
    "        # y = self.dec_embedding(y, start_token = True, end_token = True)\n",
    "        x = self.tokenize(x)\n",
    "        y = self.tokenize(y)\n",
    "\n",
    "        \n",
    "        x = self.encoder(x,\n",
    "                         encoder_self_attention_mask)\n",
    "        out = self.decoder(x,\n",
    "                           y,\n",
    "                           decoder_self_attention_mask,\n",
    "                           decoder_cross_attention_mask)\n",
    "\n",
    "        logging.debug(f'out.size() : {out.size()}')\n",
    "        out = out.reshape(self.batch_size, self.max_sequence_length * self.d_model)\n",
    "        logging.debug(f'out.size() : {out.size()}')\n",
    "        out = self.linear_layer(out)\n",
    "        logging.debug(f'out.size() : {out.size()}')\n",
    "        out = torch.flatten(out)\n",
    "        logging.debug(f'out.size() : {out.size()}')\n",
    "        # need a linear layer that maps to vocabulary size\n",
    "        out_str = self.tokenizer.decode( list(out.to(torch.int16)) )\n",
    "        \n",
    "        logging.debug(\"Transformer ENDS\")\n",
    "        \n",
    "        return out, out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4b6f7906-8d71-49c7-9a8b-b47c44a428b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Transformer BEGINS\n",
      "DEBUG:root:len(x) : 11\n",
      "DEBUG:root:len(x) : 12\n",
      "DEBUG:root:pad.size() : torch.Size([983028])\n",
      "DEBUG:root:x.size() : torch.Size([983040])\n",
      "DEBUG:root:x.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:len(x) : 3\n",
      "DEBUG:root:len(x) : 4\n",
      "DEBUG:root:pad.size() : torch.Size([983036])\n",
      "DEBUG:root:x.size() : torch.Size([983040])\n",
      "DEBUG:root:x.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:Decoder BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:Decoder ENDS\n",
      "DEBUG:root:out.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size() : torch.Size([64, 15360])\n",
      "DEBUG:root:out.size() : torch.Size([64, 10])\n",
      "DEBUG:root:out.size() : torch.Size([640])\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "out of range integral type conversion attempted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m t1_decoder_cross_attention \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m)\u001b[38;5;241m.\u001b[39mto(get_device())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 22\u001b[0m     t2, t2_str \u001b[38;5;241m=\u001b[39m \u001b[43mtrfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m             \u001b[49m\u001b[43mt1_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m             \u001b[49m\u001b[43mt1_encoder_self_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m             \u001b[49m\u001b[43mt1_decoder_self_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m             \u001b[49m\u001b[43mt1_decoder_cross_attention\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(t1_x.shape, t2.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t2\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[161], line 97\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask)\u001b[0m\n\u001b[1;32m     95\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.size() : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# need a linear layer that maps to vocabulary size\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m out_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer ENDS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, out_str\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/tiktoken/core.py:254\u001b[0m, in \u001b[0;36mEncoding.decode\u001b[0;34m(self, tokens, errors)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens: Sequence[\u001b[38;5;28mint\u001b[39m], errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decodes a list of tokens into a string.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    WARNING: the default behaviour of this function is lossy, since decoded bytes are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors)\n",
      "\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"
     ]
    }
   ],
   "source": [
    "trfm = Transformer(batch_size = 64,\n",
    "                   max_sequence_length = 20,\n",
    "                   char_per_sequence = 64,\n",
    "                   d_model = 768,\n",
    "                  ffn_hidden = 768,\n",
    "                  num_heads = 8,\n",
    "                  drop_prob = 0.1,\n",
    "                  num_layers = 1).to(get_device())\n",
    "\n",
    "# t1_x = torch.rand(64,20,768).to(get_device())\n",
    "# t1_y = torch.rand(64,20,768).to(get_device())\n",
    "t1_x = \"Hi! Australia is a continent. Moon is a planet\"\n",
    "t1_y = \"Bye!\"\n",
    "# t1_encoder_self_attention = torch.rand(1,4,4).to(get_device())\n",
    "# t1_decoder_self_attention = torch.rand(1,4,4).to(get_device())\n",
    "# t1_decoder_cross_attention = torch.rand(1,4,4).to(get_device())\n",
    "t1_encoder_self_attention = torch.rand(64, 8, 20, 20).to(get_device())\n",
    "t1_decoder_self_attention = torch.rand(64, 8, 20,20).to(get_device())\n",
    "t1_decoder_cross_attention = torch.rand(64,8, 20,20).to(get_device())\n",
    "\n",
    "with torch.no_grad():\n",
    "    t2, t2_str = trfm(t1_x,\n",
    "             t1_y,\n",
    "             t1_encoder_self_attention,\n",
    "             t1_decoder_self_attention,\n",
    "             t1_decoder_cross_attention)\n",
    "    # print(t1_x.shape, t2.shape)\n",
    "    print(t2.shape)\n",
    "    print(t2_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea63e4-82d3-4b6f-b480-39526716e028",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5147a5b-1f55-46a3-8137-bcb9e5d2fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'validation.csv']\n"
     ]
    }
   ],
   "source": [
    "CNNDM_BASE_PATH = os.path.expanduser(\"~/data/news/cnn_dailymail\")\n",
    "print(os.listdir(CNNDM_BASE_PATH))\n",
    "CNNDM_TRAIN_PATH = os.path.join(CNNDM_BASE_PATH,\"train.csv\")\n",
    "CNNDM_TEST_PATH = os.path.join(CNNDM_BASE_PATH,\"test.csv\")\n",
    "CNNDM_VAL_PATH = os.path.join(CNNDM_BASE_PATH,\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "206862dd-c56c-4f2a-a55e-e0c5c4813a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDmDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CNN DailyMail News Summarization dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,filename:str):\n",
    "        super(CnnDmDataset,self).__init__()\n",
    "        self.df = pd.read_csv(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"\n",
    "            returns a tuple (text, summary)\n",
    "        \"\"\"\n",
    "        # print( self.df.iloc[idx][\"article\"] )\n",
    "        # print( self.df.iloc[idx][\"highlights\"] )\n",
    "        return self.df.iloc[idx][\"article\"], self.df.iloc[idx][\"highlights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92d7e9ed-1cb4-4c22-94ae-3b3d66bfc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATALOADER_BATCH_SIZE = 1\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CnnDmDataset(CNNDM_TRAIN_PATH)\n",
    "test_dataset = CnnDmDataset(CNNDM_TEST_PATH)\n",
    "val_dataset = CnnDmDataset(CNNDM_VAL_PATH)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = DATALOADER_BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = DATALOADER_BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = DATALOADER_BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9536a48-46c9-44c8-8ffb-7428e3f7f3f6",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5517c3cd-e23f-4039-ad9e-cd286c2ffedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:nn.Module,\n",
    "                num_epochs: int,\n",
    "                device: torch.device,\n",
    "                batch_size:int,\n",
    "                sequence_length:int,\n",
    "                char_per_sequence:int,\n",
    "                num_heads:int,\n",
    "                d_model:int):\n",
    "    # number of sentences in text\n",
    "    # batch_size = 15\n",
    "    # dimensions of each word\n",
    "    # d_model = 768\n",
    "    # number of words in a sentence\n",
    "    # sequence_length = 4\n",
    "    # number of heads in multi head attention\n",
    "    # num_heads = 8\n",
    "\n",
    "    # train and validation losses\n",
    "    train_losses, val_losses = [],[]\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= 0.001)\n",
    "    \n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        \"\"\" Training Phase \"\"\"\n",
    "        # Set model to train mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for articles, highlights in tqdm(train_loader, desc=\"Training\") :   \n",
    "            # x = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "            # y = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "            x_article = articles[0]\n",
    "            y_highlight = highlights[0]\n",
    "            encoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_cross_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_article, y_highlight, encoder_self_attention_mask, decoder_cross_attention_mask, decoder_cross_attention_mask)\n",
    "            logging.debug(f'output.size() {output.size()}')\n",
    "            loss = criterion(output, y_highlight)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # print(f'loss.item(): {loss.item()}')\n",
    "            # running_loss += loss.item() * y.size(0)\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            train_loss = running_loss / 1\n",
    "            train_losses.append(train_loss)\n",
    "    \n",
    "            \"\"\" Validation Phase \"\"\"\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # reusing past values\n",
    "            x = torch.rand(batch_size,sequence_length, d_model).to(device)\n",
    "            y = torch.rand(batch_size,sequence_length,d_model).to(device)\n",
    "            encoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_self_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "            decoder_cross_attention_mask = torch.rand(batch_size, num_heads, sequence_length, sequence_length).to(device)\n",
    "\n",
    "            output = model(x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask)\n",
    "            loss = criterion(output, y)\n",
    "\n",
    "        val_loss = running_loss / 1\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Log epoch stats\n",
    "        logging.info(f\"Epoch {epoch+1}/{num_epochs} ; Train loss : {train_loss} ; Valid loss : {val_loss}\")\n",
    "\n",
    "    # returning losses\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a332ed7c-23de-4651-a3be-de1d0c2fdd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "trfm_model = Transformer(batch_size = 64,\n",
    "                         max_sequence_length = 20,\n",
    "                         char_per_sequence = 64,\n",
    "                         d_model=768,\n",
    "                         ffn_hidden=768,\n",
    "                         num_heads = 8,\n",
    "                         drop_prob=0.1,\n",
    "                         num_layers=6).to(get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f2d8ad7-79db-4e19-9e6a-068fd162a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trfm_model)\n",
    "# with open(\"model.txt\", \"w\") as f:\n",
    "#     f.write(str(trfm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59e95ac8-4834-498f-9950-4898c982a64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549aa82aa21e4c17a82207606eaaf99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd82805451e148bb98c47433365896b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/287113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Transformer BEGINS\n",
      "DEBUG:root:Sentences : ['Paris (CNN) -- French police arrested dozens of Greenpeace activists Tuesday who had forced their way into a nuclear power plant.', \"During the early morning break-in, the activists hung anti-nuclear banners from the Fessenheim plant, France's oldest in operation and a flashpoint for anti-nuclear campaigners who say it is unsafe and should have been closed long ago.\", '\"Today, militants of various nationalities, coming from all over Europe, protested and occupied Fessenheim, the oldest French nuclear center,\" Greenpeace said on its website.', 'EDF, which operates the plant in eastern France, said 56 people had been detained.', 'Local authorities said police remained on site as a precautionary measure.', '\"No activist entered inside the buildings.', 'These events had no impact on the safety of facilities, which are operating normally,\" local authorities said in a written statement.', 'Greenpeace wants Fessenheim, which has been in operation since 1977, to be closed immediately.', 'The activists hung a banner from the roof of the plant that said \"stop risking Europe\" and called on French President Francois Hollande and German Chancellor Angela Merkel to commit to generating energy from alternative sources.', 'Hollande has pledged to close the plant by the end of 2016.', \"CNN's Elaine Ly, Sandrine Amiel, Boriana Milanova and Marie-Louise Gumuchian contributed to this report .\"]\n",
      "DEBUG:root:sents_indices : [[0, 48, 65, 82, 73, 83, 1, 9, 35, 46, 46, 10, 1, 14, 14, 1, 38, 82, 69, 78, 67, 72, 1, 80, 79, 76, 73, 67, 69, 1, 65, 82, 82, 69, 83, 84, 69, 68, 1, 68, 79, 90, 69, 78, 83, 1, 79, 70, 1, 39, 82, 69, 69, 78, 80, 69, 65, 67, 69, 1, 65, 67, 84, 96], [0, 36, 85, 82, 73, 78, 71, 1, 84, 72, 69, 1, 69, 65, 82, 76, 89, 1, 77, 79, 82, 78, 73, 78, 71, 1, 66, 82, 69, 65, 75, 14, 73, 78, 13, 1, 84, 72, 69, 1, 65, 67, 84, 73, 86, 73, 83, 84, 83, 1, 72, 85, 78, 71, 1, 65, 78, 84, 73, 14, 78, 85, 67, 96], [0, 3, 52, 79, 68, 65, 89, 13, 1, 77, 73, 76, 73, 84, 65, 78, 84, 83, 1, 79, 70, 1, 86, 65, 82, 73, 79, 85, 83, 1, 78, 65, 84, 73, 79, 78, 65, 76, 73, 84, 73, 69, 83, 13, 1, 67, 79, 77, 73, 78, 71, 1, 70, 82, 79, 77, 1, 65, 76, 76, 1, 79, 86, 96], [0, 37, 36, 38, 13, 1, 87, 72, 73, 67, 72, 1, 79, 80, 69, 82, 65, 84, 69, 83, 1, 84, 72, 69, 1, 80, 76, 65, 78, 84, 1, 73, 78, 1, 69, 65, 83, 84, 69, 82, 78, 1, 38, 82, 65, 78, 67, 69, 13, 1, 83, 65, 73, 68, 1, 22, 23, 1, 80, 69, 79, 80, 76, 96], [0, 44, 79, 67, 65, 76, 1, 65, 85, 84, 72, 79, 82, 73, 84, 73, 69, 83, 1, 83, 65, 73, 68, 1, 80, 79, 76, 73, 67, 69, 1, 82, 69, 77, 65, 73, 78, 69, 68, 1, 79, 78, 1, 83, 73, 84, 69, 1, 65, 83, 1, 65, 1, 80, 82, 69, 67, 65, 85, 84, 73, 79, 78, 96], [0, 3, 46, 79, 1, 65, 67, 84, 73, 86, 73, 83, 84, 1, 69, 78, 84, 69, 82, 69, 68, 1, 73, 78, 83, 73, 68, 69, 1, 84, 72, 69, 1, 66, 85, 73, 76, 68, 73, 78, 71, 83, 15, 96, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95], [0, 52, 72, 69, 83, 69, 1, 69, 86, 69, 78, 84, 83, 1, 72, 65, 68, 1, 78, 79, 1, 73, 77, 80, 65, 67, 84, 1, 79, 78, 1, 84, 72, 69, 1, 83, 65, 70, 69, 84, 89, 1, 79, 70, 1, 70, 65, 67, 73, 76, 73, 84, 73, 69, 83, 13, 1, 87, 72, 73, 67, 72, 1, 96], [0, 39, 82, 69, 69, 78, 80, 69, 65, 67, 69, 1, 87, 65, 78, 84, 83, 1, 38, 69, 83, 83, 69, 78, 72, 69, 73, 77, 13, 1, 87, 72, 73, 67, 72, 1, 72, 65, 83, 1, 66, 69, 69, 78, 1, 73, 78, 1, 79, 80, 69, 82, 65, 84, 73, 79, 78, 1, 83, 73, 78, 67, 69, 96], [0, 52, 72, 69, 1, 65, 67, 84, 73, 86, 73, 83, 84, 83, 1, 72, 85, 78, 71, 1, 65, 1, 66, 65, 78, 78, 69, 82, 1, 70, 82, 79, 77, 1, 84, 72, 69, 1, 82, 79, 79, 70, 1, 79, 70, 1, 84, 72, 69, 1, 80, 76, 65, 78, 84, 1, 84, 72, 65, 84, 1, 83, 65, 96], [0, 40, 79, 76, 76, 65, 78, 68, 69, 1, 72, 65, 83, 1, 80, 76, 69, 68, 71, 69, 68, 1, 84, 79, 1, 67, 76, 79, 83, 69, 1, 84, 72, 69, 1, 80, 76, 65, 78, 84, 1, 66, 89, 1, 84, 72, 69, 1, 69, 78, 68, 1, 79, 70, 1, 19, 17, 18, 23, 15, 96, 95, 95, 95], [0, 35, 46, 46, 8, 83, 1, 37, 76, 65, 73, 78, 69, 1, 44, 89, 13, 1, 51, 65, 78, 68, 82, 73, 78, 69, 1, 33, 77, 73, 69, 76, 13, 1, 34, 79, 82, 73, 65, 78, 65, 1, 45, 73, 76, 65, 78, 79, 86, 65, 1, 65, 78, 68, 1, 45, 65, 82, 73, 69, 14, 44, 79, 96]]\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([11, 64]), sents_tokenize.device : cuda:0\n",
      "DEBUG:root:Linear Layer\n",
      "DEBUG:root:linear_layer.device : cuda:0\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([11, 15360])\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([11, 20, 768])\n",
      "DEBUG:root:fill_tensor.size() : torch.Size([53, 20, 768])\n",
      "DEBUG:root:out.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:Sentences : ['Environmental activists hang banner at nuclear plant .', \"The plant's operations were not disrupted, officials say .\", 'The Fessenheim plant opened in 1977 .']\n",
      "DEBUG:root:sents_indices : [[0, 37, 78, 86, 73, 82, 79, 78, 77, 69, 78, 84, 65, 76, 1, 65, 67, 84, 73, 86, 73, 83, 84, 83, 1, 72, 65, 78, 71, 1, 66, 65, 78, 78, 69, 82, 1, 65, 84, 1, 78, 85, 67, 76, 69, 65, 82, 1, 80, 76, 65, 78, 84, 1, 15, 96, 95, 95, 95, 95, 95, 95, 95, 95], [0, 52, 72, 69, 1, 80, 76, 65, 78, 84, 8, 83, 1, 79, 80, 69, 82, 65, 84, 73, 79, 78, 83, 1, 87, 69, 82, 69, 1, 78, 79, 84, 1, 68, 73, 83, 82, 85, 80, 84, 69, 68, 13, 1, 79, 70, 70, 73, 67, 73, 65, 76, 83, 1, 83, 65, 89, 1, 15, 96, 95, 95, 95, 95], [0, 52, 72, 69, 1, 38, 69, 83, 83, 69, 78, 72, 69, 73, 77, 1, 80, 76, 65, 78, 84, 1, 79, 80, 69, 78, 69, 68, 1, 73, 78, 1, 18, 26, 24, 24, 1, 15, 96, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95]]\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([3, 64]), sents_tokenize.device : cuda:0\n",
      "DEBUG:root:Linear Layer\n",
      "DEBUG:root:linear_layer.device : cuda:0\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([3, 15360])\n",
      "DEBUG:root:sents_tokenized.size() : torch.Size([3, 20, 768])\n",
      "DEBUG:root:fill_tensor.size() : torch.Size([61, 20, 768])\n",
      "DEBUG:root:out.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:EncoderLayer BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:EncoderLayer ENDS\n",
      "DEBUG:root:Decoder BEGINS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadAttention BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:mask.size() : torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 2304])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 20, 8, 288])\n",
      "DEBUG:root:qkv.size(): torch.Size([64, 8, 20, 288])\n",
      "DEBUG:root:q.size(): torch.Size([64, 8, 20, 96]), k.size(): torch.Size([64, 8, 20, 96]), v.size(): torch.Size([64, 8, 20, 96])\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:values.size(): torch.Size([64, 8, 20, 96]), attention.size(): torch.Size([64, 8, 20, 20])\n",
      "DEBUG:root:values.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:MultiHeadAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:MultiHeadCrossAttention BEGINS\n",
      "DEBUG:root:scaled .size() : torch.Size([64, 8, 20, 20])  type : <class 'torch.Tensor'>\n",
      "DEBUG:root:mask .size(): torch.Size([64, 8, 20, 20]) type : <class 'torch.Tensor'>\n",
      "DEBUG:root:MultiHeadCrossAttention ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:PositionwiseFeedForward BEGINS\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:x.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:PositionwiseFeedForward ENDS\n",
      "DEBUG:root:LayerNormalization BEGINS\n",
      "DEBUG:root:mean.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:var.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:std.size(): torch.Size([64, 20, 1])\n",
      "DEBUG:root:y.size() : torch.Size([64, 20, 768])\n",
      "DEBUG:root:out.size(): torch.Size([64, 20, 768])\n",
      "DEBUG:root:LayerNormalization ENDS\n",
      "DEBUG:root:Decoder ENDS\n",
      "DEBUG:root:Transformer ENDS\n",
      "DEBUG:root:output.size() torch.Size([64, 20, 768])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrfm_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mget_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mchar_per_sequence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[50], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, num_epochs, device, batch_size, sequence_length, char_per_sequence, num_heads, d_model)\u001b[0m\n\u001b[1;32m     40\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x_article, y_highlight, encoder_self_attention_mask, decoder_cross_attention_mask, decoder_cross_attention_mask)\n\u001b[1;32m     41\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.size() \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_highlight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/modules/loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/homl1/lib/python3.12/site-packages/torch/nn/functional.py:3781\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[1;32m   3772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3773\u001b[0m         mse_loss,\n\u001b[1;32m   3774\u001b[0m         (\u001b[38;5;28minput\u001b[39m, target),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3779\u001b[0m         reduction\u001b[38;5;241m=\u001b[39mreduction,\n\u001b[1;32m   3780\u001b[0m     )\n\u001b[0;32m-> 3781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3782\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3783\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3785\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   3787\u001b[0m     )\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(model = trfm_model,\n",
    "                                       num_epochs = 100,\n",
    "                                       device = get_device(),\n",
    "                                       batch_size = 64,\n",
    "                                      sequence_length = 20,\n",
    "                                      char_per_sequence = 64,\n",
    "                                       num_heads = 8,\n",
    "                                      d_model = 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752201a-3d16-413e-8c43-f22dd8d94e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_losses, label = \"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ab9acee-b4e4-436b-8bf6-9869a092ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU memory            : 254\n",
      "CUDA memory allocated : 437494784\n",
      "CUDA memory reserved  : 635437056\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "collect_garbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94a45d5c-aa5d-46a8-af29-ad71cd14242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5d7eab6-220d-4763-815b-7abdf1d365a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
