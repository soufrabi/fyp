{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e8f5d-e033-448c-9432-8643a28c9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer, DistilBertModel\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc51c5-1a43-4a05-973a-f2c1a2c157d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"system version\", sys.__version__)\n",
    "print(\"numpy version\", np.__version__)\n",
    "print(\"pandas version\", pd.__version__)\n",
    "print(\"seaborn version\", sns.__version__)\n",
    "print(\"torch version\", torch.__version__)\n",
    "print(\"nltk version\", nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82666821-7632-4524-bc3f-79e5bfa535f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect garbage\n",
    "print(gc.collect())\n",
    "print(torch.cuda.empty_cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a70a1-899e-461a-bb2b-0530838171ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_garbage():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc461f-72ef-4617-afbb-e37e8a2e2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deda83e5-bc25-4a11-ac8b-6922c6739222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "BERT_MODEL_CKPT = \"bert-base-uncased\"\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_CKPT)\n",
    "bert_model = BertModel.from_pretrained(BERT_MODEL_CKPT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d2cf9-26d2-49bc-9147-1f9acaced248",
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTILBERT_MODEL_CKPT = \"distilbert-base-uncased\"\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(DISTILBERT_MODEL_CKPT)\n",
    "distilbert_model = DistilBertModel.from_pretrained(DISTILBERT_MODEL_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82271b-6baa-4782-a8b2-450af8fea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download nltk models\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea26af02-65a2-4475-9a9b-39dcc54a0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNDM_BASE_PATH = os.path.expanduser(\"~/data/news/cnn_dailymail\")\n",
    "print(os.listdir(CNNDM_BASE_PATH))\n",
    "CNNDM_TRAIN_PATH = os.path.join(CNNDM_BASE_PATH,\"train.csv\")\n",
    "CNNDM_TEST_PATH = os.path.join(CNNDM_BASE_PATH,\"test.csv\")\n",
    "CNNDM_VAL_PATH = os.path.join(CNNDM_BASE_PATH,\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff3d10-deb8-4133-a332-dca2db65a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, max_sequence_length, tokenizer, model):\n",
    "    \"\"\"\n",
    "        Convert text into numerical representation\n",
    "        using BertTokenizer and BertModel\n",
    "    \"\"\"\n",
    "    sents = sent_tokenize(text)\n",
    "    # print(len(sents))\n",
    "    tokenized_sentences = tokenizer(sents,\n",
    "                          truncation=True,\n",
    "                          max_length=max_sequence_length,\n",
    "                          padding=\"max_length\",\n",
    "                          return_tensors=\"pt\").to(device)\n",
    "    input_ids = tokenized_sentences[\"input_ids\"]\n",
    "    attention_mask = tokenized_sentences[\"attention_mask\"]\n",
    "    # # print(input_ids.size())\n",
    "    # # print(attention_mask.size())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "    \n",
    "    # print(last_hidden_state.size())\n",
    "    return last_hidden_state\n",
    "    # return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6d0ed1-cfed-4347-b619-e6ba489edad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\"\"\"\n",
    "print(text)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b1e3d-dc95-419f-a92e-cc19e13d326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize(text,20, bert_tokenizer, bert_model).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b33030c-7204-4064-adc3-a4ebb7a86b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize(text, language_to_index=english_to_index, max_sequence_length=1_500, start_token=True, end_token=True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25f8002-6bb2-4d3c-bee1-f5ffbc1a9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(CNNDM_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3fa161-cd7c-44e9-9887-3fff258c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_df_slen = train_df[\"highlights\"].str.len().to_numpy()\n",
    "# print(\"Mean \", train_df_slen.mean())\n",
    "# print(\"Max \", train_df_slen.max())\n",
    "# print(\"Min \", train_df_slen.min())\n",
    "\n",
    "# # sns.histplot(train_df_slen)\n",
    "# # plt.xlabel(\"Length\")\n",
    "# # plt.ylabel(\"Count\")\n",
    "# # plt.show()\n",
    "# plt.figure(figsize=(5,3))\n",
    "# sns.kdeplot(train_df_slen, fill=True)\n",
    "# plt.xlabel(\"Length\")\n",
    "# plt.ylabel(\"Probability\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363602b-208e-4c03-a794-6885ef91c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = train_dataset[0][0]\n",
    "# print(len(text))\n",
    "# print(text)\n",
    "\n",
    "# t = bert_tokenizer.encode(text,\n",
    "#                           padding=\"max_length\",\n",
    "#                           max_length=512,\n",
    "#                           truncation=False,\n",
    "#                           return_tensors=\"pt\")\n",
    "# print(t.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d70ee9d-9bdf-4361-8a59-b3e4942809b1",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca1f29-61e7-4a3d-943b-f3f905d2ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDmDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CNN DailyMail News Summarization dataset\n",
    "    \"\"\"\n",
    "    def __init__(self,filename:str):\n",
    "        super(CnnDmDataset,self).__init__()\n",
    "        self.df = pd.read_csv(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \"\"\"\n",
    "            returns a tuple (text, summary)\n",
    "        \"\"\"\n",
    "        # print( self.df.iloc[idx][\"article\"] )\n",
    "        # print( self.df.iloc[idx][\"highlights\"] )\n",
    "        return self.df.iloc[idx][\"article\"], self.df.iloc[idx][\"highlights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6161f67-9ba8-4b79-9e91-d1a7dbecbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size, max_sequence_length\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "BATCH_SIZE = 1\n",
    "NUM_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925aab2-5eec-4be2-b3c4-53dfd20c1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CnnDmDataset(CNNDM_TRAIN_PATH)\n",
    "test_dataset = CnnDmDataset(CNNDM_TEST_PATH)\n",
    "val_dataset = CnnDmDataset(CNNDM_VAL_PATH)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18374e8f-de3b-4bfc-9e81-d30e2bca5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(tok_tokenizer, tok_model, num_epochs = 1, gc_itergap = 1_000):\n",
    "    \"\"\"\n",
    "        num_epochs\n",
    "        gc_itergap : Number of iterations after which garbage collector will be called\n",
    "    \"\"\"\n",
    "    iter_gc = 0\n",
    "    for epoch in trange(num_epochs, desc = \"Epochs\") :\n",
    "        for articles, highlights in tqdm(train_loader, desc=\"Training\"):\n",
    "            iter_gc = (iter_gc + 1 ) % gc_itergap\n",
    "            article  = articles[0]\n",
    "            highlight = highlights[0]\n",
    "    \n",
    "            # print(len(article), len(highlight))\n",
    "            t_article = tokenize(article,\n",
    "                                 max_sequence_length= MAX_SEQUENCE_LENGTH,\n",
    "                                 tokenizer= tok_tokenizer,\n",
    "                                model = tok_model)\n",
    "            t_article = t_article.to(device)\n",
    "            t_highlight = tokenize(highlight,\n",
    "                                  max_sequence_length = MAX_SEQUENCE_LENGTH,\n",
    "                                  tokenizer= tok_tokenizer,\n",
    "                                   model = tok_model)\n",
    "            t_highlight = t_highlight.to(device)\n",
    "    \n",
    "            \n",
    "\n",
    "            # if number of sentence exceeds 64 skip the article\n",
    "            if t_article.size(0) > 64 :\n",
    "                continue\n",
    "\n",
    "            # print(t_article.size(), t_highlight.size())\n",
    "            # tensor size (64,20,768)\n",
    "    \n",
    "            if iter_gc == 1 :\n",
    "                collect_garbage()\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76833e9-d7fb-4fe8-9e64-a37c07da7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\n",
    "    tok_tokenizer = distilbert_tokenizer,\n",
    "    tok_model = distilbert_model,\n",
    "    num_epochs= NUM_EPOCHS,\n",
    "    gc_itergap=1_000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
